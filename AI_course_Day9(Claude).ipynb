{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzSw4E/diojvP8wxgWLfoJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alejandrooct/AI-course/blob/main/AI_course_Day9(Claude).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AI course\n",
        "\n",
        "## Day#9: (Sunday December 24, 2023)\n",
        "\n",
        "##Assignement: Claude\n",
        "\n",
        "Name: Alejandro Thamm\n",
        "\n",
        "You are asked to:\n",
        "\n",
        "Download the article as a pdf\n",
        "\n",
        "Upload it to Claude of Anthropic (a type of GPT chat)\n",
        "\n",
        "and ask him to explain the article to you,\n",
        "\n",
        "of course you can also try and read it yourself.\n",
        "\n",
        "\n",
        "The article is Rami's doctoral article on the basis of which part of the final project was built.\n",
        "\n",
        "link to the article:\n",
        "https://www.mdpi.com/2075-4426/13/5/874\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "34FXzybADl5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2C3TC2hDL-r"
      },
      "outputs": [],
      "source": [
        "# Step 1- Download the article as a pdf file\n",
        "\n",
        "# The file is 10,970,679 bytes long.\n",
        "# I see that Claude has a 10 MB file limit.\n",
        "# 10 MB = 1024 x 1024 bytes = 10,485,760 bytes.\n",
        "# upload to Claude failed since file is bigger than Claude's file-size-limit.\n",
        "\n",
        "# I downloaded the file in xml format (169,223 bytes)\n",
        "# But I received an error trying to upload it to Claude, with the message:\n",
        "# \"Text extraction failed for one of the uploaded files\"\n",
        "\n",
        "# I downloaded the article as: \"pdf with cover\"\n",
        "# This file is only 3.5 MB long.\n",
        "# I will try yto upload this one.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 - Upload the article to Claude\n",
        "\n",
        "# Claude is an AI assistant (i.e. chatbot) developed by Anthropic.\n",
        "# It was first released in March 2023, powered by the language model Claude 1.3.\n",
        "# However, a second version â€“ powered by a language model called Claude 2,\n",
        "#   was released in July 2023.\n",
        "\n",
        "# Claude can be accesed freely (with limitations) at:\n",
        "#    https://claude.ai/chats\n",
        "\n",
        "# It is possible to upload documents to Claude\n",
        "# (in different formats, like pdf, txt, csv, etc.)\n",
        "# and ask Claude: \"Summarize this pdf document\"\n"
      ],
      "metadata": {
        "id": "S0vsGOXw-IOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3 - This is the summary that Claude produced in a few senconds\n",
        "\n",
        "# the summarized text has: 229 words, and 1,514 characters.\n"
      ],
      "metadata": {
        "id": "SpMAhcF-DeBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This PDF file presents a method for representing human movement as a static \"super object\" using tree structure skeleton color images (TSSCI). The key points are:\n",
        "\n",
        "1. A new approach is introduced to treat a series of human movements as one object represented by a 2D TSSCI image. This allows for movement analysis using standard deep learning image processing techniques.\n",
        "\n",
        "2. The method converts video of human exercises into TSSCI images using body keypoint detection algorithms like OpenPose. The X, Y coordinates and confidence scores are mapped to RGB channels.\n",
        "\n",
        "3. TSSCI images allow tasks like movement classification, measurement, prediction, generation of new movements using neural networks like CNNs, VAEs and Siamese networks.\n",
        "\n",
        "4. Two use cases are demonstrated - classifying exercises using EfficientNet-B7 CNN and scoring exercise quality compared to an expert using a Siamese twin network.\n",
        "\n",
        "5. A VAE is also used to generate new synthetic movements by sampling the latent space. Movements can also be merged to create new hybrid exercises.\n",
        "\n",
        "6. The super object method provides a generic way to represent and analyze human movement for applications like remote healthcare, using standard deep learning image processing techniques.\n",
        "\n",
        "In summary, this paper introduces a novel TSSCI image representation for human movement that enables analysis using convolutional neural networks as if the movement is a static object. This provides versatility for exercise classification, scoring, generation and other applications.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gf50BnZPDX7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3B -\n",
        "\n",
        "# prompt for Claude\n",
        "# Can you make a longer summary, let's say about 500 words?\n",
        "\n",
        "# This is: 447 words 3,096 characters\n"
      ],
      "metadata": {
        "id": "cP76DwdaPJjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a more detailed 500 word summary of the paper:\n",
        "\n",
        "This paper introduces a new method to represent a series of human movements as a single static \"super object\" using tree structure skeleton color images (TSSCI). Human exercises are converted to TSSCI images using real-time multi-person pose estimation algorithms like OpenPose and MediaPipe. The X, Y coordinates and confidence score of each key point in the extracted skeletons are mapped to the R, G, B channels respectively to create a TSSCI image. This allows the entire exercise workflow to be encapsulated as a static image object.\n",
        "\n",
        "Standard deep learning architectures like CNNs, autoencoders and Siamese networks used for image analysis can now operate on human movements. The paper demonstrates two use cases - classifying exercises using an EfficientNet-B7 CNN and scoring exercise mimicry accuracy relative to an expert therapist using a Siamese twin network. The dataset comprised videos of 6 exercises performed by 100 students and an expert PT.\n",
        "\n",
        "A variational autoencoder (VAE) is also employed to learn a latent representation and generate new synthetic movements. By sampling points from the VAE latent space and decoding them, novel realistic exercises are created. The VAE is analyzed using t-SNE to visualize clustering of the 6 exercise groups. The quality of the generated movements is evaluated by passing them through the exercise classifier CNN. Additionally, new hybrid movements are synthesized by merging latent vectors from different exercise types.\n",
        "\n",
        "The super object representation brings several advantages. It eliminates the need for laborious frame-by-frame labeling. Start and end times of movements are intrinsically encoded. Synchronization issues are avoided. Any image analysis technique like classification, segmentation, super resolution can now operate on human motion. The method is resource efficient - a short TSSCI sequence encapsulates the whole video. Loss functions can constrain network output.\n",
        "\n",
        "The scoring use case had some limitations in distinguishing between leg-centric exercises. This can be mitigated by using the EfficientNet probabilities directly or changing the scoring approach. Overall, the novel TSSCI representation enabled versatile analysis of exercises and measurement of mimicry accuracy even under challenging real-world conditions. This shows potential for remote patient monitoring applications.\n",
        "\n",
        "Future work includes exploring different network architectures, encoding therapies as a text description to control avatar motion, converting 2D motion to 3D, using multiple camera views for richer capture. The concept of artificially boosting latent spaces can be seen as \"computational creativity\". The super object method provides a general framework for working with human movement as an image.\n",
        "\n",
        "In conclusion, this paper presents a new paradigm for analyzing human motion by transforming an exercise sequence into a static image object encapsulating spatial-temporal information. This unlocks the ability to leverage powerful computer vision and deep learning techniques for tasks ranging from classification to scoring to simulation."
      ],
      "metadata": {
        "id": "QKiCRVF2PdyF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8S7uK275PJh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BGHWOYbyPgPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "60r-DKeUPgzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RvJhB3KWPgnF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}